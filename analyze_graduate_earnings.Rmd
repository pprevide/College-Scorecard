---
title: "Final Project, CSC869"
author: "Paul Previde"
date: "May 23, 2017"
output:
  pdf_document
    
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
knitr::opts_knit$set(root.dir = "/home/p/R")
library(dplyr)
library(ggplot2)
```

* * *


```{r}
# Given a R factor (categorical variable), this function returns its numeric value
# This function is used in the chunks below to convert factors to continuous attributes
as.numeric.factor <- function(x) {as.numeric(levels(x))[x]}
```

```{r}
# Read the 1.3 GB csv file, gather some basic stats about the dataset:
#   1. Number of independent and dependent variables
#   2. Number of empty cells
#   3. Number of cells in total
#   4. Proportion of cells that have missing values


scfull <- read.csv("Scorecard.csv", stringsAsFactors = FALSE)
dim(scfull)
na.cells <- sum(is.na(scfull))
na.cells
not.na.cells <- sum(!is.na(scfull))
not.na.cells
na.cells + not.na.cells
number.cells <- dim(scfull)[1]*dim(scfull)[2]
number.cells
na.cells/number.cells
mean(rowSums(is.na(scfull)))
mean(colSums(is.na(scfull)))
mean(rowSums(is.na(scfull)))/dim(scfull)[2]
mean(colSums(is.na(scfull)))/dim(scfull)[1]
sd(rowSums(is.na(scfull)))
sd(colSums(is.na(scfull)))
empty.cells <- sum(scfull == "", na.rm = TRUE)
empty.cells
empty.cells/number.cells
row.empty <- rowSums(scfull == "", na.rm = TRUE)
col.empty <- colSums(scfull == "", na.rm = TRUE)
mean.row.empty <- mean(row.empty, na.rm = TRUE)
mean.col.empty <- mean(col.empty, na.rm = TRUE)
sd.row.empty <- sd(row.empty, na.rm = TRUE)
sd.col.empty <- sd(col.empty, na.rm = TRUE)
mean.row.empty
mean.col.empty
sd.row.empty
sd.col.empty
mean.row.empty/dim(scfull)[2]
mean.col.empty/dim(scfull)[1]

```
Next, prepare a subset of the full data frame for easier visualizations.

```{r}
rm(partialdf)
partialdf <- data.frame(
  # earnings
  median.earnings = scfull$md_earn_wne_p6, 
  mean.earnings = scfull$mn_earn_wne_p6,
  mean.earnings.male = scfull$mn_earn_wne_male1_p6,
  mean.earnings.female = scfull$mn_earn_wne_male0_p6,
  # year
  year = scfull$Year,
  # student qualifications
  admit.rate = scfull$ADM_RATE,
  sat.avg = scfull$SAT_AVG,
  sat.math = scfull$SATMTMID,
  sat.verbal = scfull$SATVRMID,
  sat.writing = scfull$SATWRMID,
  act.mid = scfull$ACTCMMID,
  # student loans and debt
  median.debt = scfull$DEBT_MDN,
  grad.debt = scfull$GRAD_DEBT_MDN,  #completers only
  lo.median.debt = scfull$LO_INC_DEBT_MDN,
  med.median.debt = scfull$MD_INC_DEBT_MDN,
  hi.median.debt = scfull$HI_INC_DEBT_MDN,
  # what students are studying
  percent.cs = scfull$PCIP11,
  percent.bio = scfull$PCIP26,
  percent.math = scfull$PCIP27,
  percent.lit = scfull$PCIP23,
  percent.business = scfull$PCIP52,
  # parents' education level
  firstgen = scfull$PAR_ED_PCT_1STGEN,
  par.high = scfull$PAR_ED_PCT_HS,
  par.post = scfull$PAR_ED_PCT_PS,
  ### University information
  # type of university
  control = scfull$CONTROL,
  # tuition and fees
  tuition.instate = scfull$TUITIONFEE_IN,
  tuition.outofstate = scfull$TUITIONFEE_OUT,
  # average net price, inclusive of financial aid received by the students
  price.public = scfull$NPT4_PUB,
  price.private = scfull$NPT4_PRIV,
  # average net price by family income
  price.public.1 = scfull$NPT41_PUB,
  price.public.2 = scfull$NPT42_PUB,
  price.public.3 = scfull$NPT43_PUB,
  price.public.4 = scfull$NPT44_PUB,
  price.public.5 = scfull$NPT45_PUB,
  price.private.1 = scfull$NPT41_PRIV,
  price.private.2 = scfull$NPT42_PRIV,
  price.private.3 = scfull$NPT43_PRIV,
  price.private.4 = scfull$NPT44_PRIV,
  price.private.5 = scfull$NPT45_PRIV,
  # average net price for 0-48k family income
  price.public.48 = scfull$NPT4_048_PUB,
  price.private.48 = scfull$NPT4_048_PRIV,
  # number of students by family income
  num.public.1 = scfull$NUM41_PUB,
  num.public.2 = scfull$NUM42_PUB,
  num.public.3 = scfull$NUM43_PUB,
  num.public.4 = scfull$NUM44_PUB,
  num.public.5 = scfull$NUM45_PUB,
  num.private.1 = scfull$NUM41_PRIV,
  num.private.2 = scfull$NUM42_PRIV,
  num.private.3 = scfull$NUM43_PRIV,
  num.private.4 = scfull$NUM44_PRIV,
  num.private.5 = scfull$NUM45_PRIV,
  # number of students receiving aid
  num.public = scfull$NUM4_PUB,
  num.private = scfull$NUM4_PRIV,
  # geographic regions
  state = scfull$st_fips,
  region = scfull$region,
  # degree type awarded
  degree = scfull$sch_deg,
  # religious affiliation
  religion = scfull$RELAFFIL,
  # number of undergraduates
  studentbody = scfull$UGDS,
  # gender
  female = scfull$female,
  # race/national origin distribution
  Caucasian = scfull$UGDS_WHITE,
  African.American = scfull$UGDS_BLACK,
  Hispanic = scfull$UGDS_HISP,
  Asian = scfull$UGDS_ASIAN,
  American.Indian = scfull$UGDS_AIAN,
  Pacific.Islander = scfull$UGDS_NHPI,
  Non.Residents = scfull$UGDS_NRA,
  # institution name
  name = scfull$INSTNM,
  # faculty salaries and employment
  Faculty.salary = scfull$AVGFACSAL,
  Faculty.time = scfull$PFTFAC,
  # online only
  online = scfull$DISTANCEONLY
  ) 
```

At this point, we have a 70-column data frame containing the variables of interest  for visualizations.
```{r}
# Get the relevant subset of the variables for this project.

## Now do pre-processing on the data frames
## Convert where needed to their numeric values
## Clean up invalid values, like where a numeric variable holds a string
options(warn = -1)
partialdf$median.earnings <- as.numeric.factor(partialdf$median.earnings)
partialdf$mean.earnings <- as.numeric.factor(partialdf$mean.earnings)
partialdf$mean.earnings.male <- as.numeric.factor(partialdf$mean.earnings.male)
partialdf$mean.earnings.female <- as.numeric.factor(partialdf$mean.earnings.female)
partialdf$median.debt <- as.numeric.factor(partialdf$median.debt)
partialdf$grad.debt <- as.numeric.factor(partialdf$grad.debt)
partialdf$lo.median.debt <- as.numeric.factor(partialdf$lo.median.debt)
partialdf$med.median.debt <- as.numeric.factor(partialdf$med.median.debt)
partialdf$hi.median.debt <- as.numeric.factor(partialdf$hi.median.debt)
partialdf$firstgen <- as.numeric.factor(partialdf$firstgen)
partialdf$par.high <- as.numeric.factor(partialdf$par.high)
partialdf$par.post <- as.numeric.factor(partialdf$par.post)
partialdf$female <- as.numeric.factor(partialdf$female)
region.levels <- c("", "Far West", "Great Lakes", "Mid East", "New England", "Outlying Areas", "Plains", "Rocky Mountains", "Southeast", "Southwest", "U.S. Service Schools")
levels(partialdf$region) <- region.levels
partialdf$control <- as.factor(partialdf$control)
options(warn = 0)
# Now replace empty values with NA
partialdf[partialdf == ""] = NA
## Combine columns of loan recipients to reflect private/public school
partialdf$num.combined <- ifelse(is.na(partialdf$num.public), partialdf$num.private, partialdf$num.public)
partialdf$price.combined <- ifelse(is.na(partialdf$price.public), partialdf$price.private, partialdf$price.public)

## Now discretize the dependent variable, earnings, so that we can do classifications
## First, the four-class case
rm(classifydf)
classifydf <- data.frame(earnings = partialdf$median.earnings*0.001,
                       admit = partialdf$admit.rate,
                       satmath = partialdf$sat.math,
                       satverbal = partialdf$sat.verbal,
                       tuitionin = partialdf$tuition.instate*0.001,
                       tuitionout = partialdf$tuition.outofstate*0.001,
                       studentbody = partialdf$studentbody,
                       cs = partialdf$percent.cs,
                       bio = partialdf$percent.bio,
                       math = partialdf$percent.math,
                       business = partialdf$percent.business,
                       lit = partialdf$percent.lit
                       )
classifydf <- na.omit(classifydf)
quarts <- unname(quantile(classifydf$earnings, na.rm = TRUE))
mean(regressdf$earnings)
sd(regressdf$earnings)
#hist(classifydf$earnings, col=2, xlab = "Earnings (thousands of dollars)", main = "Histogram of median earnings", breaks = seq(0,140,5))
classifydf$earnings <- cut(classifydf$earnings, c(0, quarts[2], quarts[3], quarts[4], 200.0), labels = c("1", "2", "3", "4"))


# Now the two-class case
rm(twoclassdf)
twoclassdf <- data.frame(earnings = partialdf$median.earnings*0.001,
                       admit = partialdf$admit.rate,
                       satmath = partialdf$sat.math,
                       satverbal = partialdf$sat.verbal,
                       tuitionin = partialdf$tuition.instate*0.001,
                       tuitionout = partialdf$tuition.outofstate*0.001,
                       studentbody = partialdf$studentbody,
                       cs = partialdf$percent.cs,
                       bio = partialdf$percent.bio,
                       math = partialdf$percent.math,
                       business = partialdf$percent.business,
                       lit = partialdf$percent.lit
                       )
twoclassdf <- na.omit(twoclassdf)
twoclassdf$earnings <- cut(twoclassdf$earnings, c(0, median(twoclassdf$earnings), 200.0), labels = c("1", "2"))

```

Now proceed to the data analysis, first preparing the regression data frame.

##### Part I: No imputation of missing values.

```{r}
## Data Analysis: regression and classification techniques

## Regression
cat("Technique: Linear Regression")
library(boot)
rm(regressdf)
regressdf <- data.frame(earnings = partialdf$median.earnings*0.001,
                       admit = partialdf$admit.rate,
                       satmath = partialdf$sat.math,
                       satverbal = partialdf$sat.verbal,
                       tuitionin = partialdf$tuition.instate*0.001,
                       tuitionout = partialdf$tuition.outofstate*0.001,
                       pricecombined = partialdf$price.combined*0.001,
                       studentbody = partialdf$studentbody,
                       cs = partialdf$percent.cs,
                       bio = partialdf$percent.bio,
                       math = partialdf$percent.math,
                       business = partialdf$percent.business,
                       lit = partialdf$percent.lit
                       )
regressdf <- na.omit(regressdf)

attach(regressdf, warn.conflicts = FALSE)
lm.fit <- lm(earnings~., data = regressdf)
summary(lm.fit)


## Next use 10-fold cross validation to estimate the test MSE
glm.cvfit <- glm(earnings~., data = regressdf)
glm.err <- cv.glm(regressdf, glm.cvfit, K = 10)
lm.err <- glm.err$delta[1]

#Large error, so try a smaller model:
glm.cvfit.sm <- glm(earnings~pricecombined+admit, data = regressdf)
glm.err.sm <- cv.glm(regressdf, glm.cvfit.sm, K = 10)
glm.err.sm$delta[1]

#Smaller model does not outperform the larger one.  
# Evidence that the relationship is complex.

cat("Technique: Lasso")
## Lasso regression
library(glmnet)
x <- model.matrix(earnings~., data = regressdf)[,-1]
y <- earnings
grid <- 10^seq(10, -10, length = 1000)
lasso.mod <- glmnet(x,y,alpha=1, lambda = grid)
set.seed(1)
train <- sample(1:nrow(x), nrow(x)/2)
test <- (-train)
y.test <- y[test]
cv.out <- cv.glmnet(x[train, ], y[train], alpha = 1)
plot(cv.out)
bestlam <- cv.out$lambda.min
lasso.pred <- predict(lasso.mod, s=bestlam, newx = x[test, ])
lasso.err <- mean((lasso.pred - y.test)^2)

# Now get the predictors that lasso reduced to 0:
out <- glmnet(x,y,alpha=1, lambda = grid)
lasso.coef <- predict(out, type="coefficients", s = bestlam*50)
lasso.coef


cat("Elasticnet Regression")
## Elastic net regression
library(glmnet)
x <- model.matrix(earnings~., data = regressdf)[,-1]
y <- earnings
grid <- 10^seq(10, -10, length = 1000)
lasso.mod <- glmnet(x,y,alpha = 0.5, lambda = grid)
set.seed(1)
train <- sample(1:nrow(x), nrow(x)/2)
test <- (-train)
y.test <- y[test]
cv.out <- cv.glmnet(x[train, ], y[train], alpha=1)
plot(cv.out)
bestlam <- cv.out$lambda.min
lasso.pred <- predict(lasso.mod, s=bestlam, newx = x[test, ])
elastic.err <- mean((lasso.pred - y.test)^2)
# Now get the predictors that lasso reduced to 0:
out <- glmnet(x,y,alpha = 0.5, lambda = grid)
lasso.coef <- predict(out, type = "coefficients", s = bestlam)
lasso.coef

cat("Ridge regression")
## Ridge regression
x <- model.matrix(earnings~., data = regressdf)[,-1]
y <- earnings
grid <- 10^seq(10, -10, length = 1000)
ridge.mod <- glmnet(x,y,alpha = 0, lambda = grid)
set.seed(1)
train <- sample(1:nrow(x), nrow(x)/2)
test <- (-train)
y.test <- y[test]
cv.out <- cv.glmnet(x[train, ], y[train], alpha = 1)
plot(cv.out)
bestlam <- cv.out$lambda.min
ridge.pred <- predict(ridge.mod, s = bestlam, newx = x[test, ])
ridge.err <- mean((ridge.pred - y.test)^2)

cat("Polynomial Regresson, squares of each term")
# Polynomial regression
plm.fit <-  lm(earnings~poly(admit, 2)+
                poly(satmath, 2)+
                poly(satverbal, 2)+
                poly(tuitionin, 2)+
                poly(tuitionout, 2)+
                poly(pricecombined, 2)+
                poly(studentbody, 2)+
                poly(cs, 2)+
                poly(bio, 2)+
                poly(math, 2)+
                poly(business, 2)+
                poly(lit, 2), data = regressdf)
              
summary(plm.fit)
pglm.fit <-  glm(earnings~poly(admit, 2)+
                poly(satmath, 2)+
                poly(satverbal, 2)+
                poly(tuitionin, 2)+
                poly(tuitionout, 2)+
                poly(pricecombined, 2)+
                poly(studentbody, 2)+
                poly(cs, 2)+
                poly(bio, 2)+
                poly(math, 2)+
                poly(business, 2)+
                poly(lit, 2), data = regressdf)
pglm.error <- cv.glm(regressdf, pglm.fit, K = 10)
pglm.err <- pglm.error$delta[1]

# Now try up to the cubic terms of each independent variable
cat("Polynomial Regression, cubic terms")
plm.fit <-  lm(earnings~poly(admit, 3)+
                poly(satmath, 3)+
                poly(satverbal, 3)+
                poly(tuitionin, 3)+
                poly(tuitionout, 3)+
                poly(pricecombined, 3)+
                poly(studentbody, 3)+
                poly(cs, 3)+
                poly(bio, 3)+
                poly(math, 3)+
                poly(business, 3)+
                poly(lit, 3), data = regressdf)
summary(plm.fit)
pglm.fit <- glm(earnings~poly(admit, 3)+
                poly(satmath, 3)+
                poly(satverbal, 3)+
                poly(tuitionin, 3)+
                poly(tuitionout, 3)+
                poly(pricecombined, 3)+
                poly(studentbody, 3)+
                poly(cs, 3)+
                poly(bio, 3)+
                poly(math, 3)+
                poly(business, 3)+
                poly(lit, 3), data = regressdf)
pglmcub.error <- cv.glm(regressdf, pglm.fit, K = 10)
pglmcub.err <- pglmcub.error$delta[1]


#Logistic regression using the categorical dependent variable in the two-class case
cat("Logistic Regression")
detach(regressdf)
attach(twoclassdf, warn.conflicts = FALSE)
library(e1071)
glm.fit <- glm(earnings~., data = twoclassdf, family = binomial)

summary(glm.fit)
glm.probs <- predict(glm.fit, type = "response")
glm.pred <- rep("1", dim(twoclassdf)[1])
glm.pred[glm.probs>0.5] = "2"
table(glm.pred, earnings)
mean(glm.pred!=earnings)  #Training error rate.

# Compare to test error rate using 10-fold cv:
logreg.err.rates <- rep(NA, 10)
set.seed(100)
for (i in 1:10) {
  train.logreg <- sample(1:nrow(twoclassdf), nrow(twoclassdf)/2)
  train.logreg.set <- twoclassdf[train.logreg, ]
  test.logreg.set <- twoclassdf[(-train.logreg), ]
  glm.fit <- glm(earnings~., data = train.logreg.set, family = binomial)
  glm.probs <- predict(glm.fit, test.logreg.set, type="response")
  glm.pred <- rep("1", dim(test.logreg.set)[1])
  glm.pred[glm.probs>0.5] <- "2"
  logreg.err.rates[i] <- mean(glm.pred!=test.logreg.set$earnings)
}
logreg.err = mean(logreg.err.rates)

cat("Naive Bayes classification")
# Naive Bayes in the 2-class case:
nb.err.rates <- rep(NA,10)
for (i in 1:10) {
  train.logreg <- sample(1:nrow(twoclassdf), nrow(twoclassdf)/2)
  train.logreg.set <- twoclassdf[train.logreg, ]
  test.logreg.set <- twoclassdf[(-train.logreg), ]
  glm.fit <- naiveBayes(earnings~., data = train.logreg.set)
  glm.predics <- predict(glm.fit, test.logreg.set, type="class")
  nb.err.rates[i] <- mean(glm.predics!=test.logreg.set$earnings)
}
nb2.err <- mean(nb.err.rates)

# Now the 4 class problem
detach(twoclassdf)
attach(classifydf, warn.conflicts = FALSE)
nb.err.rates4 <- rep(NA,10)
for (i in 1:10) {
  train.logreg4 <- sample(1:nrow(classifydf), nrow(classifydf)/2)
  train.logreg.set4 <- classifydf[train.logreg4, ]
  test.logreg.set4 <- classifydf[(-train.logreg4), ]
  glm.fit4 <- naiveBayes(earnings~., data = train.logreg.set4)
  glm.predics4 <- predict(glm.fit4, test.logreg.set4, type = "class")
  nb.err.rates4[i] <- mean(glm.predics4!=test.logreg.set4$earnings)
}
nb4.err <- mean(nb.err.rates4)
detach(classifydf)
# Naive Bayes is higher
```


```{r}
#classifiers: 
library(MASS)
cat("LDA and QDA classification")
# LDA and QDA classifiers
#First try the two-class problem
attach(twoclassdf, warn.conflicts = FALSE)

lda.errors <- rep(NA, 10)
for (i in 1:10) {
  traininds <- sample(1:nrow(twoclassdf), nrow(twoclassdf)/10)
  train <- twoclassdf[traininds, ]
  test <- twoclassdf[(-traininds), ]
  lda.fit <- lda(earnings~., data = train)
  lda.pred <- predict(lda.fit, test)
  lda.results <- lda.pred$class
  lda.errors[i] <- mean(lda.results  !=  test$earnings)
}
lda2.err <- mean(lda.errors)
lda2.err


qda.errors <- rep(NA, 10)
for (i in 1:10) {
  traininds <- sample(1:nrow(twoclassdf), nrow(twoclassdf)/10)
  train <- twoclassdf[traininds, ]
  test <- twoclassdf[(-traininds), ]
  qda.fit <- qda(earnings~., data = train)
  qda.pred <- predict(qda.fit, test)
  qda.results <- qda.pred$class
  qda.errors[i] <- mean(qda.results != test$earnings)
}
qda2.err <- mean(qda.errors)

## Now compare to the case of four output classes
library(MASS)
detach(twoclassdf)
attach(classifydf, warn.conflicts = FALSE)
lda.errors <- rep(NA, 10)
for (i in 1:10) {
  traininds <- sample(1:nrow(classifydf), nrow(classifydf)/10)
  train <- classifydf[traininds, ]
  test <- classifydf[(-traininds), ]
  lda.fit <- lda(earnings~., data = train)
  lda.pred <- predict(lda.fit, test)
  lda.results <- lda.pred$class
  lda.errors[i] <- mean(lda.results != test$earnings)
}
lda4.err <- mean(lda.errors)

qda.errors <- rep(NA, 10)
for (i in 1:10) {
  traininds <- sample(1:nrow(classifydf), nrow(classifydf)/10)
  train <- classifydf[traininds, ]
  test <- classifydf[(-traininds), ]
  qda.fit <- qda(earnings~., data = train)
  qda.pred <- predict(qda.fit, test)
  qda.results <- qda.pred$class
  qda.errors[i] <- mean(qda.results != test$earnings)
}
qda4.err <- mean(qda.errors)

cat("Bagging and Random Forest classification")
## Now bagging and random forest
library(randomForest)
detach(classifydf)
attach(twoclassdf, warn.conflicts = FALSE)
#bagging test error by 10-fold cross validation
bag.errors <- rep(NA, 10)
for (i in 1:10) {
  traininds <- sample(1:nrow(twoclassdf), nrow(twoclassdf)/10)
  train <- twoclassdf[traininds, ]
  test <- twoclassdf[(-traininds), ]
  #bagging
  rf.fit <- randomForest(earnings~., data = train, importance = TRUE)
  importance(rf.fit)
  pred.rffit <- predict(rf.fit, newdata=test)
  bag.errors[i] <- mean(pred.rffit != test$earnings)
}
bag2.err <- mean(bag.errors)

#  Now random forest.  First, find optimal mtry:
rf.errors <- rep(NA, 9)
for (mtr in 2:10) {
  traininds <- sample(1:nrow(twoclassdf), nrow(twoclassdf)/10)
  train <- twoclassdf[traininds, ]
  test <- twoclassdf[(-traininds), ]
  rf.fit <- randomForest(earnings~., data = train, importance = TRUE, mtry=mtr)
  #importance(rf.fit)
  pred.rffit <- predict(rf.fit, newdata = test)
  rf.errors[mtr-1] <- mean(pred.rffit != test$earnings)
}
lowest.mtry <- which(rf.errors == min(rf.errors))
# Now use the lowest value of number of trees in ten-fold cross validation:
rf.errors <- rep(NA, 10)
for (i in 1:10) {
  traininds <- sample(1:nrow(twoclassdf), nrow(twoclassdf)/10)
  train <- twoclassdf[traininds, ]
  test <- twoclassdf[(-traininds), ]
  rf.fit <- randomForest(earnings~., data = train, importance = TRUE, mtry = lowest.mtry)
  pred.rffit <- predict(rf.fit, newdata = test)
  rf.errors[i] <- mean(pred.rffit != test$earnings)
}
rf2.err <- mean(rf.errors)
varImpPlot(rf.fit)
importance(rf.fit)

# Now do the same for the multiple-class classification problem

detach(twoclassdf)
attach(classifydf, warn.conflicts = FALSE)

#bagging test error by 10-fold cross validation
bag.errors <- rep(NA, 10)
for (i in 1:10) {
  traininds <- sample(1:nrow(classifydf), nrow(classifydf)/10)
  train <- classifydf[traininds, ]
  test <- classifydf[(-traininds), ]
  rf.fit <- randomForest(earnings~., data = train, importance = TRUE)
  #importance(rf.fit)
  pred.rffit <- predict(rf.fit, newdata = test)
  bag.errors[i] <- mean(pred.rffit != test$earnings)
}
bag4.err <- mean(bag.errors)

#  Now random forest.  First, find optimal mtry:
rf.errors <- rep(NA, 9)
for (mtr in 2:10) {
  traininds <- sample(1:nrow(classifydf), nrow(classifydf)/10)
  train <- classifydf[traininds, ]
  test <- classifydf[(-traininds), ]
  rf.fit <- randomForest(earnings~., data = train, importance = TRUE, mtry = mtr)
  pred.rffit <- predict(rf.fit, newdata = test)
  rf.errors[mtr-1] <- mean(pred.rffit != test$earnings)
}
lowest.mtry <- which(rf.errors == min(rf.errors))
# Now use the lowest value of number of trees in ten-fold cross validation:
rf.errors <- rep(NA, 10)
for (i in 1:10) {
  traininds <- sample(1:nrow(classifydf), nrow(classifydf)/10)
  train <- classifydf[traininds, ]
  test <- classifydf[(-traininds), ]
  rf.fit <- randomForest(earnings~., data = train, importance = TRUE, mtry = lowest.mtry)
  pred.rffit <- predict(rf.fit, newdata = test)
  rf.errors[i] <- mean(pred.rffit != test$earnings)
}
rf4.err <- mean(rf.errors)

varImpPlot(rf.fit)
importance(rf.fit)


## Lastly we apply Adaboost and check the performance
cat("Adaboost")
##
library(adabag)

attach(twoclassdf)
#adaboost.fit2 = boosting.cv(earnings~., data = twoclassdf, mfinal=20, v=10)
ab2.error <- adaboost.fit2$error

# Now the four-class case
attach(classifydf)
adaboost.fit4 <- boosting.cv(earnings~., data = classifydf, mfinal = 20, v = 10)
ab4.error <- adaboost.fit4$error

# Lastly, print two data frames showing the results on the screen.

Regression.Results <- data.frame(
  Technique = c("linear", "lasso", "elasticnet", "ridge", "polynomial^2", "polynomial^3"),
  Test.MSE = c(lm.err, lasso.err, elastic.err, ridge.err, pglm.err, pglmcub.err)
  )
Classification.Results <- data.frame(
  Technique = c("naive Bayes", "LDA", "QDA", "bagging", "random forest", "Adaboost"),
  Error.rate.2.classes = c(nb2.err, lda2.err, qda2.err, bag2.err, rf2.err, ab2.error),
  Error.rate.4.classes = c(nb4.err, lda4.err, qda4.err, bag4.err, rf4.err, ab4.error)
  )
print(Regression.Results, right = FALSE, row.names = FALSE)
print(Classification.Results, right = FALSE, row.names = FALSE)
```


At this point in the script, the case of not imputing values is completed.


##### Part 2: Impute missing values using variable mean (regression) and variable mean for each class after discretization (classification)

```{r}
## Now discretize the dependent variable, earnings, so that we can do classifications
## First, the four-class case
classifyimpute <- data.frame(earnings = partialdf$median.earnings*0.001,
                       admit = partialdf$admit.rate,
                       satmath = partialdf$sat.math,
                       satverbal = partialdf$sat.verbal,
                       tuitionin = partialdf$tuition.instate*0.001,
                       tuitionout = partialdf$tuition.outofstate*0.001,
                       studentbody = partialdf$studentbody,
                       cs = partialdf$percent.cs,
                       bio = partialdf$percent.bio,
                       math = partialdf$percent.math,
                       business = partialdf$percent.business,
                       lit = partialdf$percent.lit
                       )
quarts <- unname(quantile(classifyimpute$earnings, na.rm = TRUE))
hist(classifyimpute$earnings, col = 2, xlab = "Earnings (thousands of dollars)", main = "Histogram of median earnings", breaks = seq(0,140,5))
classifyimpute$earnings <- cut(classifyimpute$earnings, c(0, quarts[2], quarts[3], quarts[4], 200.0), labels = c("1", "2", "3", "4"))

# Now remove missing values for earnings, the dependent variable
classifyimpute <- classifyimpute[!is.na(classifyimpute$earnings), ] # keep only rows with earnings
# For other variables, impute missing value as class mean for that variable
colSums(is.na(classifyimpute))
classes <- c("1", "2", "3", "4")
predictors <- c("admit", "satmath", "satverbal", "tuitionin", "tuitionout", "studentbody", "cs", "bio", "math", "business", "lit")

for (p in predictors) {
  for (c in classes) {
    classifyimpute[is.na(classifyimpute[,p]) & classifyimpute$earnings == c, p] <- mean(classifyimpute[!is.na(classifyimpute[,p]) & classifyimpute$earnings == c, p])
  }
}
colSums(is.na(classifyimpute))


twoclassimpute <- data.frame(earnings = partialdf$median.earnings*0.001,
                       admit = partialdf$admit.rate,
                       satmath = partialdf$sat.math,
                       satverbal = partialdf$sat.verbal,
                       tuitionin = partialdf$tuition.instate*0.001,
                       tuitionout = partialdf$tuition.outofstate*0.001,
                       studentbody = partialdf$studentbody,
                       cs = partialdf$percent.cs,
                       bio = partialdf$percent.bio,
                       math = partialdf$percent.math,
                       business = partialdf$percent.business,
                       lit = partialdf$percent.lit
                       )
twoclassimpute$earnings <- cut(twoclassimpute$earnings, c(0, median(twoclassimpute$earnings, na.rm = TRUE), 200.0), labels = c("1", "2"))

twoclassimpute <- twoclassimpute[!is.na(twoclassimpute$earnings), ]
colSums(is.na(twoclassimpute))

classes <- c("1", "2")

for (p in predictors) {
  for (c in classes) {
    twoclassimpute[is.na(twoclassimpute[,p]) & twoclassimpute$earnings == c, p] <- mean(twoclassimpute[!is.na(twoclassimpute[,p]) & twoclassimpute$earnings == c, p])
  }
}
colSums(is.na(twoclassimpute))

```





```{r}
## Data Analysis: regression and classification techniques

## Regression
cat("Technique: Linear Regression")
library(boot)
detach(regressimpute)
rm(regressimpute)
regressimpute <- data.frame(earnings = partialdf$median.earnings*0.001,
                       admit = partialdf$admit.rate,
                       satmath = partialdf$sat.math,
                       satverbal = partialdf$sat.verbal,
                       tuitionin = partialdf$tuition.instate*0.001,
                       tuitionout = partialdf$tuition.outofstate*0.001,
                       pricecombined = partialdf$price.combined*0.001,
                       studentbody = partialdf$studentbody,
                       cs = partialdf$percent.cs,
                       bio = partialdf$percent.bio,
                       math = partialdf$percent.math,
                       business = partialdf$percent.business,
                       lit = partialdf$percent.lit
                       )
regressimpute <- regressimpute[!is.na(regressimpute$earnings), ] #do not try to impute earnings
colSums(is.na(regressimpute))
predictors <- c("admit", "satmath", "satverbal", "tuitionin", "tuitionout", "pricecombined", "studentbody", "cs", "bio", "math", "business", "lit")
for (p in predictors) {
    regressimpute[is.na(regressimpute[,p]), p] <- mean(regressimpute[!is.na(regressimpute[,p]), p])
}
colSums(is.na(regressimpute))



attach(regressimpute, warn.conflicts = FALSE)
lm.fit <- lm(earnings~., data = regressimpute)
summary(lm.fit)


## Next use 10-fold cross validation to estimate the test MSE
glm.cvfit <- glm(earnings~., data=regressimpute)
glm.err <- cv.glm(regressimpute, glm.cvfit, K = 10)
lm.err <- glm.err$delta[1]

#Large error, so try a smaller model:
glm.cvfit.sm <- glm(earnings~pricecombined+admit, data = regressimpute)
glm.err.sm <- cv.glm(regressimpute, glm.cvfit.sm, K = 10)
glm.err.sm$delta[1]

#Smaller model does not outperform the larger one.  
# Evidence that the relationship is complex.

cat("Technique: Lasso")
## Lasso regression
library(glmnet)
x <- model.matrix(earnings~., data = regressimpute)[,-1]
y <- earnings
grid <- 10^seq(10, -10, length = 1000)
lasso.mod <- glmnet(x, y, alpha = 1, lambda = grid)
set.seed(1)
train <- sample(1:nrow(x), nrow(x)/2)
test <- (-train)
y.test <- y[test]
cv.out <- cv.glmnet(x[train, ], y[train], alpha = 1)
plot(cv.out)
bestlam <- cv.out$lambda.min
lasso.pred <- predict(lasso.mod, s  = bestlam, newx = x[test, ])
lasso.err <- mean((lasso.pred - y.test)^2)

# Now get the predictors that lasso reduced to 0:
out <- glmnet(x,y,alpha=1, lambda = grid)
lasso.coef <- predict(out, type = "coefficients", s = bestlam)
lasso.coef


cat("Elasticnet Regression")
## Elastic net regression
library(glmnet)
x <- model.matrix(earnings~., data = regressimpute)[,-1]
y <- earnings
grid <- 10^seq(10, -10, length = 1000)
lasso.mod <- glmnet(x,y,alpha = 0.5, lambda = grid)
set.seed(1)
train <- sample(1:nrow(x), nrow(x)/2)
test <- (-train)
y.test <- y[test]
cv.out <- cv.glmnet(x[train, ], y[train], alpha = 1)
plot(cv.out)
bestlam <- cv.out$lambda.min
lasso.pred <- predict(lasso.mod, s = bestlam, newx = x[test, ])
elastic.err <- mean((lasso.pred - y.test)^2)

# Now get the predictors that elasticnet reduced to 0:
out <- glmnet(x,y,alpha=0.5, lambda = grid)
lasso.coef <- predict(out, type = "coefficients", s = bestlam)
lasso.coef

cat("Ridge regression")
## Ridge regression
x <- model.matrix(earnings~., data = regressimpute)[,-1]
y <- earnings
grid <- 10^seq(10, -10, length = 1000)
ridge.mod <- glmnet(x,y,alpha = 0, lambda = grid)
set.seed(1)
train <- sample(1:nrow(x), nrow(x)/2)
test <- (-train)
y.test <- y[test]
cv.out <- cv.glmnet(x[train, ], y[train], alpha = 1)
plot(cv.out)
bestlam <- cv.out$lambda.min
ridge.pred <- predict(ridge.mod, s = bestlam, newx = x[test, ])
ridge.err <- mean((ridge.pred - y.test)^2)

cat("Polynomial Regresson, squares of each term")
# Polynomial regression
plm.fit <- lm(earnings~poly(admit, 2)+
                poly(satmath, 2)+
                poly(satverbal, 2)+
                poly(tuitionin, 2)+
                poly(tuitionout, 2)+
                poly(pricecombined, 2)+
                poly(studentbody, 2)+
                poly(cs, 2)+
                poly(bio, 2)+
                poly(math, 2)+
                poly(business, 2)+
                poly(lit, 2), data = regressimpute)
              
summary(plm.fit)
pglm.fit <-  glm(earnings~poly(admit, 2)+
                poly(satmath, 2)+
                poly(satverbal, 2)+
                poly(tuitionin, 2)+
                poly(tuitionout, 2)+
                poly(pricecombined, 2)+
                poly(studentbody, 2)+
                poly(cs, 2)+
                poly(bio, 2)+
                poly(math, 2)+
                poly(business, 2)+
                poly(lit, 2), data = regressimpute)
pglm.error <- cv.glm(regressimpute, pglm.fit, K = 10)
pglm.err <- pglm.error$delta[1]

# Now try up to the cubic terms of each independent variable
cat("Polynomial Regression, cubic terms")
plm.fit <- lm(earnings~poly(admit, 3)+
                poly(satmath, 3)+
                poly(satverbal, 3)+
                poly(tuitionin, 3)+
                poly(tuitionout, 3)+
                poly(pricecombined, 3)+
                poly(studentbody, 3)+
                poly(cs, 3)+
                poly(bio, 3)+
                poly(math, 3)+
                poly(business, 3)+
                poly(lit, 3), data = regressimpute)
summary(plm.fit)
pglm.fit <- glm(earnings~poly(admit, 3)+
                poly(satmath, 3)+
                poly(satverbal, 3)+
                poly(tuitionin, 3)+
                poly(tuitionout, 3)+
                poly(pricecombined, 3)+
                poly(studentbody, 3)+
                poly(cs, 3)+
                poly(bio, 3)+
                poly(math, 3)+
                poly(business, 3)+
                poly(lit, 3), data = regressimpute)
pglmcub.error <- cv.glm(regressimpute, pglm.fit, K = 10)
pglmcub.err <- pglmcub.error$delta[1]


#Logistic regression using the categorical dependent variable in the two-class case
cat("Logistic Regression")
detach(regressimpute)
attach(twoclassimpute, warn.conflicts = FALSE)
library(e1071)
glm.fit <- glm(earnings~., data = twoclassimpute, family = binomial)

summary(glm.fit)
glm.probs <- predict(glm.fit, type = "response")
glm.pred <- rep("1", dim(twoclassimpute)[1])
glm.pred[glm.probs>0.5] <- "2"
table(glm.pred, earnings)
mean(glm.pred!=earnings)  #Training error rate.

# Compare to test error rate using 10-fold cv:
logreg.err.rates <- rep(NA, 10)
set.seed(100)
for (i in 1:10) {
  train.logreg <- sample(1:nrow(twoclassimpute), nrow(twoclassimpute)/2)
  train.logreg.set <- twoclassimpute[train.logreg, ]
  test.logreg.set <- twoclassimpute[(-train.logreg), ]
  glm.fit <- glm(earnings~., data = train.logreg.set, family = binomial)
  glm.probs <- predict(glm.fit, test.logreg.set, type = "response")
  glm.pred <- rep("1", dim(test.logreg.set)[1])
  glm.pred[glm.probs>0.5] <- "2"
  logreg.err.rates[i] <- mean(glm.pred != test.logreg.set$earnings)
}
logreg.err <- mean(logreg.err.rates)

cat("Naive Bayes classification")
# Naive Bayes in the 2-class case:
nb.err.rates <- rep(NA,10)
for (i in 1:10) {
  train.logreg <- sample(1:nrow(twoclassimpute), nrow(twoclassimpute)/2)
  train.logreg.set <- twoclassimpute[train.logreg, ]
  test.logreg.set <- twoclassimpute[(-train.logreg), ]
  glm.fit <- naiveBayes(earnings~., data = train.logreg.set)
  glm.predics <- predict(glm.fit, test.logreg.set, type = "class")
  nb.err.rates[i] <- mean(glm.predics != test.logreg.set$earnings)
}
nb2.err <- mean(nb.err.rates)

# Now the 4 class problem
detach(twoclassimpute)
attach(classifyimpute, warn.conflicts = FALSE)
nb.err.rates4 <- rep(NA,10)
for (i in 1:10) {
  train.logreg4 <- sample(1:nrow(classifyimpute), nrow(classifyimpute)/2)
  train.logreg.set4 <- classifyimpute[train.logreg4, ]
  test.logreg.set4 <- classifyimpute[(-train.logreg4), ]
  glm.fit4 <- naiveBayes(earnings~., data = train.logreg.set4)
  glm.predics4 <- predict(glm.fit4, test.logreg.set4, type="class")
  nb.err.rates4[i] <- mean(glm.predics4 != test.logreg.set4$earnings)
}
nb4.err <- mean(nb.err.rates4)
nb4.err
detach(classifyimpute)
# Naive Bayes is higher
```


```{r}
#classifiers: 
library(MASS)
cat("LDA and QDA classification")
# LDA and QDA classifiers
#First try the two-class problem
attach(twoclassimpute, warn.conflicts = FALSE)

lda.errors <- rep(NA, 10)
for (i in 1:10) {
  traininds <- sample(1:nrow(twoclassimpute), nrow(twoclassimpute)/10)
  train <- twoclassimpute[traininds, ]
  test <- twoclassimpute[(-traininds), ]
  lda.fit <- lda(earnings~., data = train)
  lda.pred <- predict(lda.fit, test)
  lda.results <- lda.pred$class
  lda.errors[i] <- mean(lda.results != test$earnings)
}
lda2.err <- mean(lda.errors)


qda.errors <- rep(NA, 10)
for (i in 1:10) {
  traininds <- sample(1:nrow(twoclassimpute), nrow(twoclassimpute)/10)
  train <- twoclassimpute[traininds, ]
  test <- twoclassimpute[(-traininds), ]
  qda.fit <- qda(earnings~., data = train)
  qda.pred <- predict(qda.fit, test)
  qda.results <- qda.pred$class
  qda.errors[i] <- mean(qda.results != test$earnings)
}
qda2.err <- mean(qda.errors)

## Now compare to the case of four output classes
library(MASS)
detach(twoclassimpute)
attach(classifyimpute, warn.conflicts = FALSE)
lda.errors <- rep(NA, 10)
for (i in 1:10) {
  traininds <- sample(1:nrow(classifyimpute), nrow(classifyimpute)/10)
  train <- classifyimpute[traininds, ]
  test <- classifyimpute[(-traininds), ]
  lda.fit <- lda(earnings~., data = train)
  lda.pred <- predict(lda.fit, test)
  lda.results <- lda.pred$class
  lda.errors[i] <- mean(lda.results != test$earnings)
}
lda4.err <- mean(lda.errors)

qda.errors <- rep(NA, 10)
for (i in 1:10) {
  traininds <- sample(1:nrow(classifyimpute), nrow(classifyimpute)/10)
  train <- classifyimpute[traininds, ]
  test <- classifyimpute[(-traininds), ]
  qda.fit <- qda(earnings~., data = train)
  qda.pred <- predict(qda.fit, test)
  qda.results <- qda.pred$class
  qda.errors[i] <- mean(qda.results != test$earnings)
}
qda4.err <- mean(qda.errors)

cat("Bagging and Random Forest classification")
## Now bagging and random forest
library(randomForest)
detach(classifyimpute)
attach(twoclassimpute, warn.conflicts = FALSE)
#bagging test error by 10-fold cross validation
bag.errors <- rep(NA, 10)
for (i in 1:10) {
  traininds <- sample(1:nrow(twoclassimpute), nrow(twoclassimpute)/10)
  train <- twoclassimpute[traininds, ]
  test <- twoclassimpute[(-traininds), ]
  #bagging
  rf.fit <- randomForest(earnings~., data = train, importance = TRUE)
  importance(rf.fit)
  pred.rffit <- predict(rf.fit, newdata=test)
  bag.errors[i] <- mean(pred.rffit != test$earnings)
}
bag2.err = mean(bag.errors)

#  Now random forest.  First, find optimal mtry:
rf.errors <- rep(NA, 9)
for (mtr in 2:10) {
  traininds <- sample(1:nrow(twoclassimpute), nrow(twoclassimpute)/10)
  train <- twoclassimpute[traininds, ]
  test <- twoclassimpute[(-traininds), ]
  rf.fit <- randomForest(earnings~., data = train, importance = TRUE, mtry = mtr)
  pred.rffit <- predict(rf.fit, newdata=test)
  rf.errors[mtr-1] <- mean(pred.rffit != test$earnings)
}

lowest.mtry <- which(rf.errors==min(rf.errors))

# Now use the lowest value of number of trees in ten-fold cross validation:
rf.errors <- rep(NA, 10)
for (i in 1:10) {
  traininds <- sample(1:nrow(twoclassimpute), nrow(twoclassimpute)/10)
  train <- twoclassimpute[traininds, ]
  test <- twoclassimpute[(-traininds), ]
  rf.fit <- randomForest(earnings~., data = train, importance = TRUE, mtry = lowest.mtry)
  pred.rffit <- predict(rf.fit, newdata = test)
  rf.errors[i] <- mean(pred.rffit != test$earnings)
}
rf2.err <- mean(rf.errors)


# Now do the same for the multiple-class classification problem

detach(twoclassimpute)
attach(classifyimpute, warn.conflicts = FALSE)

#bagging test error by 10-fold cross validation
bag.errors <- rep(NA, 10)
for (i in 1:10) {
  traininds <- sample(1:nrow(classifyimpute), nrow(classifyimpute)/10)
  train <- classifyimpute[traininds, ]
  test <- classifyimpute[(-traininds), ]
  rf.fit <- randomForest(earnings~., data = train, importance = TRUE)
  pred.rffit <- predict(rf.fit, newdata = test)
  bag.errors[i] <- mean(pred.rffit != test$earnings)
}
bag4.err <- mean(bag.errors)

#  Now random forest.  First, find optimal mtry:
rf.errors <- rep(NA, 9)
for (mtr in 2:10) {
  traininds <- sample(1:nrow(classifyimpute), nrow(classifyimpute)/10)
  train <- classifyimpute[traininds, ]
  test <- classifyimpute[(-traininds), ]
  rf.fit <- randomForest(earnings~., data = train, importance = TRUE, mtry=mtr)
  #importance(rf.fit)
  pred.rffit <- predict(rf.fit, newdata = test)
  rf.errors[mtr-1] <- mean(pred.rffit != test$earnings)
}
lowest.mtry <- which(rf.errors==min(rf.errors))

# Now use the lowest value of number of trees in ten-fold cross validation:
rf.errors <- rep(NA, 10)
for (i in 1:10) {
  traininds <- sample(1:nrow(classifyimpute), nrow(classifyimpute)/10)
  train <- classifyimpute[traininds, ]
  test <- classifyimpute[(-traininds), ]
  rf.fit <- randomForest(earnings~., data = train, importance = TRUE, mtry = lowest.mtry)
  pred.rffit <- predict(rf.fit, newdata = test)
  rf.errors[i] <- mean(pred.rffit != test$earnings)
}
rf4.err <- mean(rf.errors)

varImpPlot(rf.fit)
importance(rf.fit)


## Lastly we apply Adaboost and check the performance
cat("Adaboost")
##
library(adabag)

attach(twoclassimpute)
adaboost.fit2 <- boosting.cv(earnings~., data = twoclassimpute, mfinal = 20, v = 10)
ab2.error.impute <- adaboost.fit2$error

# Now the four-class case
attach(classifyimpute)
adaboost.fit4 <- boosting.cv(earnings~., data = classifyimpute, mfinal = 20, v = 10)
ab4.error.impute <- adaboost.fit4$error

# Lastly, print two data frames showing the results on the screen.

Regression.Results.impute = data.frame(
  Technique <- c("linear", "lasso", "elasticnet", "ridge", "polynomial^2", "polynomial^3"),
  Test.MSE <- c(lm.err, lasso.err, elastic.err, ridge.err, pglm.err, pglmcub.err)
  )
Classification.Results.impute = data.frame(
  Technique <- c("naive Bayes", "LDA", "QDA", "bagging", "random forest", "Adaboost"),
  Error.rate.2.classes <- c(nb2.err, lda2.err, qda2.err, bag2.err, rf2.err, ab2.error.impute),
  Error.rate.4.classes <- c(nb4.err, lda4.err, qda4.err, bag4.err, rf4.err, ab4.error.impute)
  )
print(Regression.Results.impute, right = FALSE, row.names = FALSE)
print(Classification.Results.impute, right = FALSE, row.names = FALSE)
```

